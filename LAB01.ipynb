{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"33b6b0bc-0150-4568-9958-bb5d323ff45a","showTitle":false,"title":""}},"outputs":[],"source":["## mount 해제\n","dbutils.fs.unmount(\"/mnt/flightdata\")"]},{"cell_type":"markdown","metadata":{},"source":["Azure Data Lake Stoage Gen2 + Azure Databricks mount 연결 설정\n","---\n","* ABFS를사용하여 ADLS Gen2또는 Blob Storage 탑재\n","이 드라이버를 사용하면 많은 애플리케이션과 프레임워크에서 Data Lake Storage Gen2를 명시적으로 참조하는 코드 없이 Azure BlobStorage의 데이터에 액세스할 수 있습니다.\n","    인증을 위해 Azure AD(Azure Active Directory) 애플리케이션 서비스 주체를 사용하여 Azure 스토리지에 대한 액세스 구성을 진행해야 합니다.  \n","    https://learn.microsoft.com/ko-kr/azure/databricks/dbfs/mounts#mount-azure-storage\n","\n","필요한 매개변수 값을 미리 text파일에 저장하여 값을 미리 담아두세요."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8629761a-2b09-48dc-b29b-1d57800dc2ee","showTitle":false,"title":""}},"outputs":[],"source":["configs {\"fs.azure.account.auth.type\": \"OAuth\",\n","       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n","       \"fs.azure.account.oauth2.client.id\": \"<application-id>\", --\n","       \"fs.azure.account.oauth2.client.secret\": \"<client-secret>\",\n","       \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/<tenant-id>/oauth2/token\",\n","       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n","\n","dbutils.fs.mount(\n","source = \"abfss://<container-name>@<storage-account-name>dfs.core.windows.net/\",\n","mount_point = \"/mnt/flightdata\",\n","extra_configs = configs)"]},{"cell_type":"markdown","metadata":{},"source":["데이터 읽어오기"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b23c72e4-da96-489b-ad76-e164cb4e33a2","showTitle":false,"title":""}},"outputs":[],"source":["# Use the previously established DBFS mount point to read the data.\n","# create a data frame to read data.\n","\n","flightDF = spark.read.format('csv').options(header='true', inferschema='true').load(\"/mnt/flightdata/folder1/*.csv\")\n","display(flightDF)\n","# read the airline csv file and write the output to parquet format for easy query.\n","flightDF.write.mode(\"append\").parquet(\"/mnt/flightdata/parquet/flights\")\n","print(\"Done\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5543d246-75a8-4fa3-88a4-b4b1973a3675","showTitle":false,"title":""}},"outputs":[],"source":["import os.path\n","import IPython\n","from pyspark.sql import SQLContext\n","display(dbutils.fs.ls(\"/mnt/flightdata\"))"]},{"cell_type":"markdown","metadata":{},"source":["dbutils. put() 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"a7afe006-57f2-45e4-b543-078646324b4b","showTitle":false,"title":""}},"outputs":[],"source":["dbutils.fs.put(\"/mnt/flightdata/1.txt\", \"Hello, World!\", True)\n","dbutils.fs.ls(\"/mnt/flightdata/parquet/flights\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"a28f7123-4455-4e82-9604-2193dc63fd44","showTitle":false,"title":""}},"outputs":[],"source":["# Copy this into a Cmd cell in your notebook.\n","acDF = spark.read.format('csv').options(\n","    header='true', inferschema='true').load(\"/mnt/flightdata/folder1/On_Time.csv\")\n","acDF.write.parquet('/mnt/flightdata/parquet/airlinecodes')\n","\n","# read the existing parquet file for the flights database that was created earlier\n","flightDF = spark.read.format('parquet').options(\n","    header='true', inferschema='true').load(\"/mnt/flightdata/parquet/flights\")\n","\n","# print the schema of the dataframes\n","acDF.printSchema()\n","flightDF.printSchema()\n","\n","# print the flight database size\n","print(\"Number of flights in the database: \", flightDF.count())\n","\n","# show the first 20 rows (20 is the default)\n","# to show the first n rows, run: df.show(n)\n","acDF.show(100, False)\n","flightDF.show(20, False)\n","\n","# Display to run visualizations\n","# preferably run this in a separate cmd cell\n","display(flightDF)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d4c548e6-9e58-4d68-ae60-6a3fd9626816","showTitle":false,"title":""}},"outputs":[],"source":["display(flightDF)"]},{"cell_type":"markdown","metadata":{},"source":["createOrReplaceTempView 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"77e53d9b-76f5-439c-b16b-bae33fda3437","showTitle":false,"title":""}},"outputs":[],"source":["# Run each of these queries, preferably in a separate cmd cell for separate analysis\n","# create a temporary sql view for querying flight information\n","FlightTable = spark.read.parquet('/mnt/flightdata/parquet/flights')\n","FlightTable.createOrReplaceTempView('FlightTable')\n","\n","# create a temporary sql view for querying airline code information\n","AirlineCodes = spark.read.parquet('/mnt/flightdata/parquet/airlinecodes')\n","AirlineCodes.createOrReplaceTempView('AirlineCodes')\n","\n","# using spark sql, query the parquet file to return total flights in January and February 2016\n","out1 = spark.sql(\"SELECT * FROM FlightTable WHERE Month=1\")\n","NumJan2016Flights = out1.count()\n","out2 = spark.sql(\"SELECT * FROM FlightTable WHERE Month=2\")\n","NumFeb2016Flights = out2.count()\n","print(\"Jan 2016: \", NumJan2016Flights, \" Feb 2016: \", NumFeb2016Flights)\n","Total = NumJan2016Flights+NumFeb2016Flights\n","print(\"Total flights combined: \", Total)\n","\n","# List out all the airports in Texas\n","#out = spark.sql(\n","#    \"SELECT distinct(OriginCityName) FROM FlightTable where OriginStateName = 'Texas'\")\n","#print('Airports in Texas: ', out.show(100))\n","\n","# find all airlines that fly from Texas\n","#out1 = spark.sql(\n","#    \"SELECT distinct(Reporting_Airline) FROM FlightTable WHERE OriginStateName='Texas'\")\n","#print('Airlines that fly to/from Texas: ', out1.show(100, False))"]},{"cell_type":"markdown","metadata":{},"source":["매직명령 사용하기"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3daecfe0-e868-41ff-8625-61739071dd4c","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT * FROM FlightTable\n"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":3116823068966341,"dataframes":["_sqldf"]},"pythonIndentUnit":4},"notebookName":"test_20221024","notebookOrigID":1148476220907475,"widgets":{}},"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.4"},"vscode":{"interpreter":{"hash":"1a47e62313ec3de59581e344c7436f71082b6d970008688e52c1cb8f51dccc8f"}}},"nbformat":4,"nbformat_minor":0}
